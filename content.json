[{"title":"你不知道的SpringBoot (Part 1)","date":"2021-04-19T13:00:30.000Z","path":"2021/04/19/you-dont-know-springboot-01/","text":"随着SpringBoot日渐流行，有关SpringBoot的各类“心经”、“秘籍”、“从入门到精通”之类的文章或者书籍琳琅满目、层出不穷，本文无意与这些典籍争锋，而是从实际应用出发，结合官方文档，收集并整理一些不常见却很有用的知识点，同时蹭一下You Don’t Know JS Yet的热度，姑且就叫它你不知道的SpringBoot。 创建项目start.spring.io可以说是最好的SpringBoot项目创建工具，没有之一。start.spring.io可以满足绝大多数创建由SpringBoot驱动的应用程序的场景，它具备以下特征： 生成的工程开箱即用，几乎不做任何修改就可以运行； IDE友好，可以快速导入进主流IDE中； 依赖版本准确，不会引发依赖不匹配而导致的各类诡异问题，例如SpringBoot与Spring Cloud大版本的匹配都是准确的； 多构建工具支持，可以自由选择Maven或Gradle； 多语言支持，可以自由选择Java、Groovy或Kotlin； 多Java版本支持，可以自由选择LTS或最新版的JDK； 可以通过Explore功能拷贝需要的依赖代码片段而不需要下载整个项目； 可以通过Share功能把创建项目的属性以URL的方式分享给其他人。 除以上特征之外，start.spring.io本身提供了restful API，可以通过简单的http调用来创建项目而不需要访问他的web UI，例如下面的例子，通过curl来创建一个新的项目并下载到本地： 12$ curl https://start.spring.io/starter.zip -d dependencies=web,devtools \\ -d bootVersion=2.3.5.RELEASE -o my-project.zip 这种API调用的方式也是大多数IDE生成SpringBoot项目的底层手段。除使用curl外，还可以通过Spring Boot CLI的方式创建项目，与curl方式是非类似， 123$ spring init --build=gradle \\ --java-version=1.8 --dependencies=websocket \\ --packaging=jar sample-app.zip Spring Boot CLI的安装可以参考官方文档。 以上start.spring.io以及其衍生工具的使用，除此之外，我们甚至可以搭建自己的Spring Initializr Reference，原理类似与自己运行一个start.spring.io，这里我们就不展开讨论了。更多详情请参考官方文档， 内置的构建工具如果采用上述start.spring.io生成Maven或Gradle项目时，项目中会自带Maven Wrapper或Grade Wrapper，以Maven项目为例，我们会在项目下看到下面的目录结构， 12345678910├── .mvn│ └── wrapper│ ├── MavenWrapperDownloader.java│ ├── maven-wrapper.jar│ └── maven-wrapper.properties├── HELP.md├── mvnw├── mvnw.cmd├── pom.xml└── src 其中的.mvn、mvnw就是项目自带Maven Wrapper。一般我们在使用Maven时，用到的都是提前安装好的全局的Maven，所有需要构建的程序也都会共享这一个全局的Maven。但是对于某些项目来说，构建是可能需要用到特定的Maven版本，这时做全局安装费时费力，还要污染全局，而使用Maven Wrapper就可以避免类似问题，进而高效地使用特定版本的Maven，Maven Wrapper的工作流程是这样的： 在执行mvnw命令时，会检查/.m2/wrapper目录下是否有对应版本的Maven安装，如果有，则继续构建； 如果没有，则根据当前目录下.mvn/wrapper/maven-wrapper.properties中的的distributionUrl属性值来下载Maven，下载后再完成构建； 有很多同学在生成SpringBoot项目后，直接就把Maven Wrapper相关的文件删除掉了，这里还是建议保留，并且也应该把这些文件一并提交到代码仓库里，这样对于其他开发人员和CI/CD工具也是友好的，大家都可以使用一致的环境来构建项目。 特有的转换器Converter SPI是Spring Framework中非常重要的基本概念，Spring Framework也内置转换器可以实现从String到其他常用数据类型的转换。SpringBoot进一步强化了转换器，引入了3个特有的转换器，可以方便的处理Duration、Peroid以及DataSize，详情如下表所示： Java类型 单位 示例 java.time.Duration nsusmssmhd 50s3d java.time.Period ymwd 2m1y3d org.springframework.util.unit.DataSize BKBMBGBTB 512B2MB 完整的示例代码： 12345678910111213141516171819@ConstructorBinding@ConfigurationProperties(\"demo\")@Getterclass DemoProperties &#123; private final Duration duration; private final Period period; private final DataSize dataSize; DemoProperties(@DefaultValue(\"30s\") Duration duration, @DefaultValue(\"2y3d\") Period period, @DefaultValue(\"5MB\") DataSize dataSize) &#123; this.duration = duration; this.period = period; this.dataSize = dataSize; &#125;&#125; 更多详情请参考官方文档。 特有的事件Spring Framework本身实现了一整套事件体系，并定义了一组内置的事件，但这些事件基本上是Context级别的，而不是Application级别的。SpringBoot拓展了Spring Framework的事件体系，并引入了Application Level的一组事件： 应用程序启动时会触发ApplicationStartingEvent； 应用程序运行的Environment准备好后，在创建Applicatoin Context之前，会触发ApplicationEnvironmentPreparedEvent； 在ApplicationContext准备好后，所有ApplicationContextInitializers被执行后，但在所有的Bean定义加载之前，会触发ApplicationContextInitializedEvent事件； Bean定义加载后，会触发ApplicationPreparedEvent事件； 在Application Context刷新后，command-line runner被调用之前，会触发ApplicationStartedEvent事件； 在LivenessState.CORRECT被检测到之后，换言之，应用程序已经被认为处于活跃状态，会触发AvailabilityChangeEvent事件； 在所有的command-line runner被执行后，会触发ApplicationReadyEvent事件。(原文是“any”而不是“all”，表述不是非常准确，特意提了这个issue)； 在ReadinessState.ACCEPTING_TRAFFIC被简则之后，换言之，应用程序已被认为可以处理外部请求，会再触发AvailabilityChangeEvent事件； 在应用程序启动过程中产生任何异常，会触发ApplicationFailedEvent事件。 以上Application Level的各类事件中，最常用的监听ApplicationReadyEvent事件来做其他初始化操作，因为这个时间点，所有的Bean及其依赖都已经创建，这些Bean已经可以使用，例如下面的代码所示： 1234567891011121314151617181920212223242526@Dataclass Student &#123; private Long id; private String name;&#125;@Repositoryinterface StudentRepo &#123; Stream&lt;Student&gt; findAll();&#125;@Service@RequiredArgsConstructorclass StudentService &#123; private final StudentRepo studentRepo; private final AtomicReference&lt;Map&lt;Long, Student&gt;&gt; _caches = new AtomicReference&lt;&gt;(); @EventListener(ApplicationReadyEvent.class) void init() &#123; this._caches.set(this.studentRepo.findAll() .collect(Collectors.toConcurrentMap(Student::getId, Function.identity()))); &#125;&#125; 更多详情请参考官方文档。 运行初始化代码CommandLineRunner和ApplicationRunner都可以用来运行初始化代码，CommandLineRunner通过一个字符串数组来访问命令行参数，而ApplicationRunner是通过ApplicationArguments来访问。除此之外，可以配置多个CommandLineRunner或者ApplicationRunner，其优先级和执行顺序遵循一下规则： ApplicationRunner会优先于CommandLineRunner执行； 多个同类型的Runner可以通过@Order注解来指定运行顺序，但@Order只有放在class上才生效。 考虑下面的代码， 12345678910111213141516171819202122// incorrect code, don't use it@Bean@Order(2)public CommandLineRunner commandLineRunner1() &#123; return args -&gt; &#123; log.info(\"I'm commandline runner 1\"); &#125;;&#125;@Bean@Order(1)public CommandLineRunner commandLineRunner2() &#123; return args -&gt; &#123; log.info(\"I'm commandline runner 2\"); &#125;;&#125;@Bean@Order(10)public ApplicationRunner applicationRunner3() &#123; return args -&gt; &#123; log.info(\"I'm application runner 3\"); &#125;;&#125; 其输出结果为， 123m.d.y.YouDontKnowSpringbootApplication : I'm application runner 3m.d.y.YouDontKnowSpringbootApplication : I'm commandline runner 1m.d.y.YouDontKnowSpringbootApplication : I'm commandline runner 2 可以看到applicationRunner3最先被运行，但commandLineRunner1与commandLineRunner2并没有按照@Order指定的顺序运行，其中的原理可以参考这里。只有按照下面的方式才能做到有序， 123456789101112131415161718192021@Order(2)@Component@Slf4jclass CommandLineRunner1 implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; log.info(\"I'm commandline runner 1\"); &#125;&#125;@Order(1)@Component@Slf4jclass CommandLineRunner2 implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; log.info(\"I'm commandline runner 2\"); &#125;&#125; 其输出结果为， 12me.danielpf.ydtk.CommandLineRunner2 : I'm commandline runner 2me.danielpf.ydtk.CommandLineRunner1 : I'm commandline runner 1 上面已经提到过，ApplicationReadyEvent会在所有的Runner运行之后才会触发，所以尽量避免既在Runner中执行过长、过慢的逻辑又要依赖于监听ApplicationReadyEvent，考虑下面的代码， 1234567891011@Beanpulic CommandLineRunner commandLineRunner() &#123; return args -&gt; &#123; log.info(\"start commandline runner...\"); TimeUnit.SECONDS.sleep(10); &#125;;@EentListener(ApplicationReadyEvent.class)pulic void ready() &#123; log.info(\"application ready...\");&#125; 其输出结果为， 122021-04-21 15:57:32.379 INFO 56531 --- [ main] m.d.y.YouDontKnowSpringbootApplication : start commandline runner...2021-04-21 15:57:42.386 INFO 56531 --- [ main] m.d.y.YouDontKnowSpringbootApplication : application ready...注意 更多详情请参考官方文档。 Web Application类型SpringBoot会根据依赖尝试创建合适的Web Environment，其默认规则可以参考下面的表格， Starter Application Conext Web Application Type Web Container spring-boot-starter-web only AnnotationConfigServletWebServer SERVLET Tomcat spring-boot-starter-webflux only AnnotationConfigReactiveWebServer REACTIVE Netty spring-boot-starter-webspring-boot-starter-webflux AnnotationConfigServletWebServer SERVLET Tomcat spring-boot-starter AnnotationConfig NONE N/A 需要注意的是， 如果spring-boot-starter-web与spring-boot-starter-webflux混用，那么Web Environment还是会被设置为SERVLET，这种情况是为了兼容在SERVLET应用中使用Reactive API，例如WebClient； 可以通过编程的方式，手动设置WebApplicationType，甚至关闭Web Environment，例如下面的代码是通过flunt-builder的方式关闭Web Environment， 123456public static void main(String[] args) &#123; new SpringApplicationBuilder() .sources(YouDontKnowSpringbootApplication.class) .web(WebApplicationType.NONE) .run(args);&#125; 更多详情请参考官方文档。 使用JSON配置应用大多数场景下，我们一般会使用properties文件或者YAML文件，结合命令行参数来配置SpringBoot应用程序，除此之外，我们还可以通过JSON来配置应用程序，我们可以把基于JSON的配置理解成为一个增强版的命令行。我们写在JSON里面的配置，都会被merge进当前的Environment。 JSON配置可以通过以下几种方式传递给应用程序，这里借官方文档的几个示例说明， 通过UN*X shell的环境变量传递：1$ SPRING_APPLICATION_JSON='&#123;\"acme\":&#123;\"name\":\"test\"&#125;&#125;' java -jar myapp.jar 通过system property传递：1$ java -Dspring.application.json='&#123;\"acme\":&#123;\"name\":\"test\"&#125;&#125;' -jar myapp.jar 通过命令行参数传递：1$ java -jar myapp.jar --spring.application.json='&#123;\"acme\":&#123;\"name\":\"test\"&#125;&#125;' 如果应用程序部署在传统的web中间件中，可以通过JNDI传递，变量名称为：1java:comp/env/spring.application.json 更多详情请参考官方文档。 基于Profile的Logback在SpringBoot中使用Logback也能享受到Spring Profile所带来的便利，基于Profile的Logback配置文件为logback-spring.xml，放置在classpath下会被SpringBoot自动加载。我们可以使用springProfile来控制不同Profile下有那些appender会生效，例如这样， 1234567891011&lt;springProfile name=\"dev\"&gt; &lt;appender name=\"ROLL_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; ...... &lt;/appender&gt; &lt;/springProfile&gt;&lt;springProfile name=\"staging | prod\"&gt; &lt;appender name=\"MAILER\" class=\"ch.qos.logback.classic.net.SMTPAppender\"&gt; ...... &lt;/appender&gt; &lt;/springProfile&gt; 也可以使用springProperty来定义一些属性，并在后面的配置引用这些属性， 1234&lt;springProperty scope=\"context\" name=\"mailSubjectPrefix\" source=\"mail.subject.prefix\" defaultValue=\"\"/&gt;&lt;springProperty scope=\"context\" name=\"component\" source=\"mail.component\" defaultValue=\"[my-app]\"/&gt;&lt;springProperty name=\"LOG_PATH\" source=\"logging.path\" defaultValue=\"/var/log/my-app/\" /&gt;&lt;springProperty name=\"LOG_FILE\" source=\"logging.path\" defaultValue=\"main\" /&gt; 更多详情请参考官方文档。 探活Spring Boot Actuator提供了非常强大的系统监控功能。在K8s等容器环境部署SpringBoot应用时，我们可以可以借助Spring Boot Actuator内置的Health Indicator来实现探活，一般情况下借助/actuator/health/liveness与/actuator/health/readiness这两个endpoint， 12345678910111213livenessProbe: httpGet: path: /actuator/health/liveness port: &lt;actuator-port&gt; failureThreshold: ... periodSeconds: ...readinessProbe: httpGet: path: /actuator/health/readiness port: &lt;actuator-port&gt; failureThreshold: ... periodSeconds: ... 我们还可以实现自己的HealthIndicators， 1234567891011121314151617import org.springframework.boot.actuate.health.Health;import org.springframework.boot.actuate.health.HealthIndicator;import org.springframework.stereotype.Component;@Componentpublic class MyHealthIndicator implements HealthIndicator &#123; @Override public Health health() &#123; int errorCode = check(); // perform some specific health check if (errorCode != 0) &#123; return Health.down().withDetail(\"Error Code\", errorCode).build(); &#125; return Health.up().build(); &#125;&#125; 更多详情请参考官方文档。 多数据源在检测到有数据库访问相关的依赖后，SpringBoot会尝试Auto Config数据源，我们只需要设定数据源的各类属性即可。但在某些业务场景下，我们需要多个数据源，我们可以借助SpringBoot内置的一些工具，比较方便地配置多个数据源。下面的代码展示了从配置上彻底分开的两个不同数据源， @Bean @Primary @ConfigurationProperties(\"app.datasource.first\") public DataSourceProperties firstDataSourceProperties() { return new DataSourceProperties(); } @Bean @Primary @ConfigurationProperties(\"app.datasource.first.configuration\") public HikariDataSource firstDataSource() { return firstDataSourceProperties().initializeDataSourceBuilder().type(HikariDataSource.class).build(); } @Bean @ConfigurationProperties(\"app.datasource.second\") public DataSourceProperties secondDataSourceProperties() { return new DataSourceProperties(); } @Bean @ConfigurationProperties(\"app.datasource.second.configuration\") public BasicDataSource secondDataSource() { return secondDataSourceProperties().initializeDataSourceBuilder().type(BasicDataSource.class).build(); } 上述代码的要点如下： 可以借助DataSourceProperties来绑定特定前缀的数据源属性(这些属性仍为标准属性，只是前缀不同)，并通过initializeDataSourceBuilder()和type()创建特定类型的数据源； 可以借助@ConfigurationProperties再次将自定义的属性绑定到已经在上一步创建的数据源对象上； 一定要通过@Primary来指定默认的数据源。 关于多数据源的动态切换，不在本文做过多讨论，可以参考这篇Blog。更多详情请参考官方文档。","tags":[{"name":"spring","slug":"spring","permalink":"https://danielpf.me/tags/spring/"},{"name":"springboot","slug":"springboot","permalink":"https://danielpf.me/tags/springboot/"}]},{"title":"Kotlin + Spring Cloud Stream构建实时消息系统","date":"2020-10-05T14:19:22.000Z","path":"2020/10/05/reactive-messaging-kt/","text":"作为一门新兴的现代化编程语言，Kotlin正获得广泛的关注，Spring社区也将支持Kotlin语言作为下一阶段的重要工作，甚至抛出了Spring Loves Kotin和A Match Made in Heaven这般暧昧的论调。本文暂不去讨论Kotlin语言的细节，而是通过使用Kotlin和Spring Cloud Stream构建实时消息系统来领略一番Spring Loves Kotlin的魅力。 系统架构实时消息系统可适用于多种业务场景，本文将实现一个非常典型的案例，其它复杂案例都可以通过此案例扩展，其架构如下图所示： graph LR; A(1.Producer)-->|MQ|B(2.Processor); B-->|MQ|C(3.Consumer); C-->|Pub-Sub|D(4.Notifier); D-->|Http|E((5.Client)); 下面对各模块进行简要说明， Producer: 作为数据源产生数据，并将数据通过MQ传给后面的Processor进行处理; Processor: 在MQ中读取Producer产生的消息并加以处理，并将处理后的结果通过MQ传给后面的Consumer; Consumer: 在MQ中读取Processor产生的消息并转发至Redis中的Pub-Sub Topic; Notifier: 订阅Redis中的Pub-Sub Topic并处理由Consumer发布的消息，并通过SSE转发给订阅消息的Client; Client: 通过Http订阅由Notifier发布的SSE事件; 本文中的案例将会实现模块1～4，模块5Client不做实现，可通过curl等http客户端进行模拟。 项目模块按照上面讨论的系统架构，我们创建一个多模块的Gradle项目，并用Kotlin DSL作为描述语言，项目结构如下图所示： 123456789101112131415161718192021222324.├── gradle│ └── wrapper├── rmkt-consumer│ ├── src│ └── build.gradle.kts├── rmkt-core│ ├── src│ └── build.gradle.kts├── rmkt-notifier│ ├── src│ └── build.gradle.kts├── rmkt-processor│ ├── src│ └── build.gradle.kts├── rmkt-producer│ ├── src│ └── build.gradle.kts├── HELP.md├── README.md├── build.gradle.kts├── gradlew├── gradlew.bat└── settings.gradle.kts 这些模块都可以与上面讨论过的系统架构一一对应，唯一的不同点是项目中多出了一个core模块，该模块用于放置各模块的公用部分，例如domain对象、常量定义以及公共方法等，稍后我们会详细说明。本文不会讨论Kotlin DSL的细节，由于没有涉及过多的知识点，各模块的build.gradle.kts文件(类似于Maven中的pom.xml文件)应该不会影响大家对代码的理解。 下面简要说明一下该系统的业务逻辑： Producter每隔1秒钟产生一个Product消息，每个Product包含唯一的id和随机产生的name、price以及createdTime; Processor处理Product消息，根据预先定义的ExchangeRate来计算Product在多种货币下的价格，并生成ProductExchange对象; Consumer收到ProductExchange对象后，过滤价格小于500的，并将其转发至Redis的Pub-Sub Topic中; Notifier订阅Pub-Sub Topic，并将ProductExchange按照Client请求的货币种类转换成ProductLocal对象，并以SSE事件的形式返回给Client. 代码实现接下来我们根据上面讨论的系统架构、项目模块以及业务逻辑来实现代码。 Core功能模块的公共部分都放置在Core模块内，我们可以在Core.kt文件里定义功能模块所需的domain、常量以及工具类。首先我们先使用Kotlin的特性之一，数据类来构建Product和ProductExchange， 1234567891011data class Product( val id: String, val name: String, val price: Double, val createdTime: LocalDateTime)data class ProductExchange( val product: Product, val localPrices: Map&lt;String, Double&gt;) 然后再使用枚举类构建ExchangeRate， 1234567enum class ExchangeRate(val rate: Double) &#123; USD(1.00), CNY(6.7906), JPY(105.3246), EUR(0.8535), GBP(0.773)&#125; 最后我们再使用伴生对象来模拟Java中的常量定义， 123456class Constants &#123; companion object &#123; const val PRODUCT_EXCHANGE_TOPIC = \"topic:pe\" const val DEFAULT_CURRENCY = \"USD\" &#125;&#125; 最后我们再使用对象声明来实现一个单例模式，这是一个单例的ObjectMapper，预定义了一些特性，可用于后续的JSON对象的序列化/反序列化，需要使用该对象的时候，只需要使用ObjectMapperExtension.instance即可。 12345object ObjectMapperExtension &#123; val instance: ObjectMapper = jacksonObjectMapper() .registerModules(Jdk8Module(), JavaTimeModule()) .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)&#125; Producer接下来我们将借助Spring Cloud Stream分别来实现Producer、Processor以及Consumer模块。最新版的Spring Cloud Stream彻底拥抱了函数式，使用Routing Function替代了早期版本中的@EnableBinding、@StreamEmitter以及@StreamListener等注解，其对应关系为， Annotation Routing Function Source, @StreamEmitter java.util.function.Supplier Sink, @StreamListener java.util.function.Consumer Processor, @EnableBinding(Processor.class) java.util.function.Function 对于Producer，我们只需注册一个类型为Supplier的Bean，而Reactive的Producer，只需要能够一个Supplier&lt;Flux&lt;T&gt;&gt;即可，代码如下， 1234567891011121314151617181920212223@SpringBootApplicationclass ProducerApplicationfun main(args: Array&lt;String&gt;) &#123; runApplication&lt;ProducerApplication&gt;(*args)&#125;@Configurationclass SourceConfig &#123; @Bean fun productSource(): Supplier&lt;Flux&lt;Product&gt;&gt; = Supplier &#123; Flux.interval(Duration.ofSeconds(1)).map &#123; Product( UUID.randomUUID().toString(), RandomStringUtils.randomAlphanumeric(5, 10), Random.nextDouble(1000.00), LocalDateTime.now() ) &#125;.onBackpressureDrop().log() &#125;&#125; 以上代码会每秒钟产生一个ID为UUID，名字为5～10随机字母，价格为0～1000的随机商品。数据由Supplier产生后，我们需要告知Spring Cloud Stream这些数据的Destination，这个Destination应该指向RabbitMQ中名为products的Exchange，我们只需要在application.properties加入下面配置即可，Spring Cloud Stream会自动创建这个Exchange， 1spring.cloud.stream.bindings.productSource-out-0.destination=products 这里的Binding名称就是Supplier的Bean名称productSource。 Processor接下来我们实现Processor，按照上一节的说明，Processor应该是一个Function，入参是Flux&lt;Product&gt;，出参是Flux&lt;ProductExchange&gt;，并完成localPrices的计算，详细代码如下， 123456789101112131415161718192021222324@SpringBootApplicationclass ProcessorApplicationfun main(args: Array&lt;String&gt;) &#123; runApplication&lt;ProcessorApplication&gt;(*args)&#125;@Configurationclass ProcessorConfig &#123; @Bean fun productProcessor(): Function&lt;Flux&lt;Product&gt;, Flux&lt;ProductExchange&gt;&gt; = Function &#123; it.log() .map &#123; product -&gt; ProductExchange( product, ExchangeRate.values() .map &#123; exchange -&gt; exchange.name to exchange.rate * product.price &#125; .toMap() ) &#125;.log() &#125;&#125; 由于Processor对应Input与Output两个Binding，所以配置中需要配置两个destination，Input来自于products，Output指向product_exchanges， 1234spring.cloud.stream.bindings.productProcessor-in-0.destination=productsspring.cloud.stream.bindings.productProcessor-in-0.group=product_processorspring.cloud.stream.bindings.productProcessor-out-0.destination=product_exchanges Input的Binding需要额外配置group的名称，这样可以有多个Consumer同时消费Exchange中的数据来提高并行处理能力。 Consumer接下来我们实现Consumer，按照最新的Spring Cloud Stream规范，Consumer应该对应一个java.util.function.Consumer实现。这里有一点需要注意，由于我们采用的是Reactive形式，而Reactive有自己的Void类型，而不是Java的void关键字，所以这里的Consumer&lt;Flux&lt;T&gt;&gt;应该使用Function&lt;Flux&lt;?&gt;, Mono&lt;Void&gt;&gt;代替，相反的，如果是非Reactive模式下，还是应该正常使用java.util.function.Consumer作为函数类型。 另外，Consumer在过滤掉低价格的ProductExchange后，还需要将消息转发至Redis中的Pub-Sub Topic中，这里我们还需要配置一个JSON的序列化/反序列化器，这样Pub到Redis中的消息会以JSON数据格式表示，而不是默认的普通String ，这里的ObjectMapper将使用在Core模块里定义好的ObjectMapperExtension， 1234567891011121314151617181920212223242526272829303132@SpringBootApplicationclass ConsumerApplicationfun main(args: Array&lt;String&gt;) &#123; runApplication&lt;ConsumerApplication&gt;(*args)&#125;@Configurationclass ConsumerConfig &#123; @Bean fun productExchangeConsumer(operations: ReactiveRedisOperations&lt;String, ProductExchange&gt;) : Function&lt;Flux&lt;ProductExchange&gt;, Mono&lt;Void&gt;&gt; = Function &#123; it.filter &#123; pe -&gt; pe.product.price &gt; 500.00 &#125; .log() .flatMap &#123; pe -&gt; operations.convertAndSend(PRODUCT_EXCHANGE_TOPIC, pe) &#125; .then() &#125; @Bean fun productExchangeReactiveRedisOperations(factory: ReactiveRedisConnectionFactory) : ReactiveRedisOperations&lt;String, ProductExchange&gt; = Jackson2JsonRedisSerializer(ProductExchange::class.java).also &#123; it.setObjectMapper(ObjectMapperExtension.instance) &#125;.let &#123; RedisSerializationContext.newSerializationContext&lt;String, ProductExchange&gt;(StringRedisSerializer()) .value(it).build() &#125;.let &#123; ReactiveRedisTemplate&lt;String, ProductExchange&gt;(factory, it) &#125;&#125; 这段代码中，我们定义了两个@Bean，一个是作为Consumer用来处理数据的Function，另外一个就是用来发布消息的ReactiveRedisTemplate，并且配置了JSON的序列化/反序列化器。当然，我们也需要配置一下Consumer的destination和group， 12spring.cloud.stream.bindings.productExchangeConsumer-in-0.destination=product_exchangesspring.cloud.stream.bindings.productExchangeConsumer-in-0.group=product_exchanges_consumer Notifier最后是Notifier。Notifier本身不需要Spring Cloud Stream的支持，只需要订阅Redis中的Pub-Sub Topic，与Consumer，用于监听Redis的ReactiveRedisMessageListenerContainer也需要自定义一个JSON的序列化/反序列化器，我们把这部分逻辑封装在NotifyService中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class NotifyService(private val container: ReactiveRedisMessageListenerContainer) &#123; private val processor = ReplayProcessor.create&lt;ProductExchange&gt;() @PostConstruct fun init() = processor.sink().let &#123; sink -&gt; container.receive( listOf(ChannelTopic.of(PRODUCT_EXCHANGE_TOPIC)), RedisSerializationContext.SerializationPair.fromSerializer(StringRedisSerializer()), RedisSerializationContext.SerializationPair.fromSerializer( Jackson2JsonRedisSerializer(ProductExchange::class.java).also &#123; it.setObjectMapper(ObjectMapperExtension.instance) &#125; ) ) .map &#123; m -&gt; m.message &#125; .doOnNext &#123; sink.next(it) &#125; .log() .subscribe(&#123;&#125;, &#123;&#125;) &#125; fun notifyEvents(currency: String): Flux&lt;ServerSentEvent&lt;ProductLocal&gt;&gt; = processor.map &#123; p -&gt; (if (currency.toUpperCase() !in p.localPrices.keys) DEFAULT_CURRENCY else currency.toUpperCase()) .let &#123; ProductLocal( p.product.id, p.product.name, p.product.createdTime, BigDecimal(p.localPrices[it] ?: 0.0).setScale(4, RoundingMode.HALF_EVEN), it ) &#125;.let &#123; ServerSentEvent.builder(it).id(it.id).build() &#125; &#125;&#125;data class ProductLocal( val id: String, val name: String, val createdTime: LocalDateTime, val localPrice: BigDecimal, val localCurrency: String) 上述代码比较容易理解，init方法用于在容器启动时，完成对Pub-Sub Topic的监听，同时将订阅的数据转发至一个Reactor的Processor中，这个Processor就是之后SSE事件的数据源。另外我们还提供一个notifyEvents方法，用于接收currency参数，将缓存在Processor中的数据加工成ProductLocal，并作为SSE发给客户端。 接下来我们要向Spring容器注册这个service，以及API的Endpoint。与之前采用的@Configuration方式不同，这里我们尝试使用Spring Kotlin DSL来注册Bean。 12345678910111213141516171819202122232425262728@SpringBootApplicationclass NotifierApplicationfun main(args: Array&lt;String&gt;) &#123; runApplication&lt;NotifierApplication&gt;(*args) &#123; addInitializers( beans &#123; bean&lt;ReactiveRedisMessageListenerContainer&gt;() bean&lt;NotifyService&gt;() bean &#123; ref&lt;NotifyService&gt;().let &#123; notifyService -&gt; router &#123; GET(\"/pl/&#123;currency&#125;\") &#123; ServerResponse.ok().body( BodyInserters.fromServerSentEvents( notifyService.notifyEvents( it.pathVariable(\"currency\") ) ) ) &#125; &#125; &#125; &#125; &#125; ) &#125;&#125; 以上代码初看比较奇特，其中的beans、bean、router都属于基于Kotlin Type-Safe Builders的DSL。这里我们不展开说明，只需要了解Spring Kotlin DSL提供了一种更为简单直接的配置方式。至此，所有模块都实现完毕。 运行下面我们开始运行代码。 在运行之前，保证本地已经运行了RabbitMQ和Redis。 注意 首先是Producer，从console中我们可以看到Product数据源源不断产生并虽送到了MQ， 12345678910112020-10-05 14:32:38.518 INFO 5925 --- [oundedElastic-1] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory.publisher#42e0654e:0/SimpleConnection@75a0a52e [delegate=amqp://guest@127.0.0.1:5672/, localPort= 52496]2020-10-05 14:32:39.273 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=6c2b236e-40f8-44ff-a1cf-7a94910944ac, name=cv9pATmM, price=395.31181210651545, createdTime=2020-10-05T14:32:39.272939))2020-10-05 14:32:40.272 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=8a10bf35-5e37-4e74-96da-7c8471e56937, name=8Qoagte, price=765.5943349019311, createdTime=2020-10-05T14:32:40.272813))2020-10-05 14:32:41.272 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=03751003-daa9-4f19-be69-5ac434b70b7f, name=FihxILXp9, price=351.88328720033377, createdTime=2020-10-05T14:32:41.272239))2020-10-05 14:32:42.268 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=d7788f46-009a-4a95-ae06-df88ca133d87, name=6DmSTJE, price=504.01347237601976, createdTime=2020-10-05T14:32:42.268429))2020-10-05 14:32:43.267 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=26a06bf0-91a7-4d2f-b15a-f666e072716b, name=J7G766jO0, price=597.8645160007096, createdTime=2020-10-05T14:32:43.267724))2020-10-05 14:32:44.268 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=9c0fd106-e00c-44b5-8187-2566737395bb, name=kyWUhn3J, price=152.01109964002336, createdTime=2020-10-05T14:32:44.268194))2020-10-05 14:32:45.268 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=110c91ae-41b2-4223-bf33-3759c4f4dc52, name=vlULf6xJ8, price=506.1068481643988, createdTime=2020-10-05T14:32:45.268531))2020-10-05 14:32:46.270 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=45c84ed6-7208-4e19-9ead-e9b778512a77, name=8kzXJ, price=15.856892691681669, createdTime=2020-10-05T14:32:46.270622))2020-10-05 14:32:47.270 INFO 5925 --- [ parallel-1] reactor.Flux.OnBackpressureDrop.1 : onNext(Product(id=569b85c0-7bdd-45ae-a83a-db237779d90f, name=pAZswdD, price=205.12230260372854, createdTime=2020-10-05T14:32:47.270448))...... 接下来是Processor，从console中我们可以看到Product被处理，ProductExchange数据不断产生， 123456789101112132020-10-05 14:32:38.772 INFO 5898 --- [uct_processor-1] o.s.a.r.c.CachingConnectionFactory : Attempting to connect to: [localhost:5672]2020-10-05 14:32:38.778 INFO 5898 --- [uct_processor-1] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory.publisher#a62b940:0/SimpleConnection@c4b6d1e [delegate=amqp://guest@127.0.0.1:5672/, localPort= 52498]2020-10-05 14:32:39.276 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.1 : onNext(Product(id=6c2b236e-40f8-44ff-a1cf-7a94910944ac, name=cv9pATmM, price=395.31181210651545, createdTime=2020-10-05T14:32:39.272939))2020-10-05 14:32:39.276 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.2 : onNext(ProductExchange(product=Product(id=6c2b236e-40f8-44ff-a1cf-7a94910944ac, name=cv9pATmM, price=395.31181210651545, createdTime=2020-10-05T14:32:39.272939), localPrices=&#123;USD=395.31181210651545, CNY=2684.404391290504, JPY=41636.0584853939, EUR=337.39863163291096, GBP=305.57603075833646&#125;))2020-10-05 14:32:40.277 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.1 : onNext(Product(id=8a10bf35-5e37-4e74-96da-7c8471e56937, name=8Qoagte, price=765.5943349019311, createdTime=2020-10-05T14:32:40.272813))2020-10-05 14:32:40.277 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.2 : onNext(ProductExchange(product=Product(id=8a10bf35-5e37-4e74-96da-7c8471e56937, name=8Qoagte, price=765.5943349019311, createdTime=2020-10-05T14:32:40.272813), localPrices=&#123;USD=765.5943349019311, CNY=5198.844890585054, JPY=80635.91708581193, EUR=653.4347648387983, GBP=591.8044208791928&#125;))2020-10-05 14:32:41.276 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.1 : onNext(Product(id=03751003-daa9-4f19-be69-5ac434b70b7f, name=FihxILXp9, price=351.88328720033377, createdTime=2020-10-05T14:32:41.272239))2020-10-05 14:32:41.276 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.2 : onNext(ProductExchange(product=Product(id=03751003-daa9-4f19-be69-5ac434b70b7f, name=FihxILXp9, price=351.88328720033377, createdTime=2020-10-05T14:32:41.272239), localPrices=&#123;USD=351.88328720033377, CNY=2389.4986500625864, JPY=37061.966471060274, EUR=300.3323856254849, GBP=272.005781005858&#125;))2020-10-05 14:32:42.277 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.1 : onNext(Product(id=d7788f46-009a-4a95-ae06-df88ca133d87, name=6DmSTJE, price=504.01347237601976, createdTime=2020-10-05T14:32:42.268429))2020-10-05 14:32:42.277 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.2 : onNext(ProductExchange(product=Product(id=d7788f46-009a-4a95-ae06-df88ca133d87, name=6DmSTJE, price=504.01347237601976, createdTime=2020-10-05T14:32:42.268429), localPrices=&#123;USD=504.01347237601976, CNY=3422.5538855166, JPY=53085.01737261533, EUR=430.17549867293286, GBP=389.6024141466633&#125;))2020-10-05 14:32:43.270 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.1 : onNext(Product(id=26a06bf0-91a7-4d2f-b15a-f666e072716b, name=J7G766jO0, price=597.8645160007096, createdTime=2020-10-05T14:32:43.267724))2020-10-05 14:32:43.270 INFO 5898 --- [uct_processor-1] reactor.Flux.Map.2 : onNext(ProductExchange(product=Product(id=26a06bf0-91a7-4d2f-b15a-f666e072716b, name=J7G766jO0, price=597.8645160007096, createdTime=2020-10-05T14:32:43.267724), localPrices=&#123;USD=597.8645160007096, CNY=4059.858782354419, JPY=62969.84100196834, EUR=510.27736440660567, GBP=462.14927086854857&#125;))...... 然后是Consumer，我们可以直接通过redis-cli来订阅Redis的Pub-Sub Topic， 123456789101112131415161718192021127.0.0.1:6379&gt; subscribe topic:peReading messages... (press Ctrl-C to quit)1) \"subscribe\"2) \"topic:pe\"3) (integer) 11) \"message\"2) \"topic:pe\"3) \"&#123;\\\"product\\\":&#123;\\\"id\\\":\\\"3e155fa7-9f42-4685-aeba-534342bc2f05\\\",\\\"name\\\":\\\"tvnzfHSJh\\\",\\\"price\\\":908.6521294566128,\\\"createdTime\\\":\\\"2020-10-05T14:36:03.278801\\\"&#125;,\\\"localPrices\\\":&#123;\\\"USD\\\":908.6521294566128,\\\"CNY\\\":6170.293150288076,\\\"JPY\\\":95703.42207416597,\\\"EUR\\\":775.5345924912191,\\\"GBP\\\":702.3880960699616&#125;&#125;\"1) \"message\"2) \"topic:pe\"3) \"&#123;\\\"product\\\":&#123;\\\"id\\\":\\\"563638ee-deef-4102-92f8-f8a95dbcea71\\\",\\\"name\\\":\\\"4n93HpIDy\\\",\\\"price\\\":730.6959805104445,\\\"createdTime\\\":\\\"2020-10-05T14:36:06.273764\\\"&#125;,\\\"localPrices\\\":&#123;\\\"USD\\\":730.6959805104445,\\\"CNY\\\":4961.864125254225,\\\"JPY\\\":76960.26186887037,\\\"EUR\\\":623.6490193656645,\\\"GBP\\\":564.8279929345737&#125;&#125;\"1) \"message\"2) \"topic:pe\"3) \"&#123;\\\"product\\\":&#123;\\\"id\\\":\\\"f578f6ef-2858-4f2c-8ddb-53aff31e7b60\\\",\\\"name\\\":\\\"tBJPIJg\\\",\\\"price\\\":997.1833424008273,\\\"createdTime\\\":\\\"2020-10-05T14:36:07.274668\\\"&#125;,\\\"localPrices\\\":&#123;\\\"USD\\\":997.1833424008273,\\\"CNY\\\":6771.473204907058,\\\"JPY\\\":105027.93666503018,\\\"EUR\\\":851.0959827391061,\\\"GBP\\\":770.8227236758395&#125;&#125;\"1) \"message\"2) \"topic:pe\"3) \"&#123;\\\"product\\\":&#123;\\\"id\\\":\\\"8825530f-4c92-4989-80a7-11344752eb95\\\",\\\"name\\\":\\\"ffAND\\\",\\\"price\\\":656.5872951974707,\\\"createdTime\\\":\\\"2020-10-05T14:36:08.278398\\\"&#125;,\\\"localPrices\\\":&#123;\\\"USD\\\":656.5872951974707,\\\"CNY\\\":4458.621686767945,\\\"JPY\\\":69154.79423175553,\\\"EUR\\\":560.3972564510412,\\\"GBP\\\":507.5419791876448&#125;&#125;\"1) \"message\"2) \"topic:pe\"3) \"&#123;\\\"product\\\":&#123;\\\"id\\\":\\\"bed9f33f-2c00-4e6f-a73a-27c2d4472a25\\\",\\\"name\\\":\\\"t1eCrzm\\\",\\\"price\\\":569.2236131405484,\\\"createdTime\\\":\\\"2020-10-05T14:36:09.276028\\\"&#125;,\\\"localPrices\\\":&#123;\\\"USD\\\":569.2236131405484,\\\"CNY\\\":3865.3698673922086,\\\"JPY\\\":59953.24936458301,\\\"EUR\\\":485.8323538154581,\\\"GBP\\\":440.00985295764394&#125;&#125;\"...... 最后是Notifier，我们可以直接使用curl命令来调用API， 12345678910111213141516curl http://localhost:8080/pl/jpyid:8a10bf35-5e37-4e74-96da-7c8471e56937data:&#123;\"id\":\"8a10bf35-5e37-4e74-96da-7c8471e56937\",\"name\":\"8Qoagte\",\"createdTime\":\"2020-10-05T14:32:40.272813\",\"localPrice\":80635.9171,\"localCurrency\":\"JPY\"&#125;id:d7788f46-009a-4a95-ae06-df88ca133d87data:&#123;\"id\":\"d7788f46-009a-4a95-ae06-df88ca133d87\",\"name\":\"6DmSTJE\",\"createdTime\":\"2020-10-05T14:32:42.268429\",\"localPrice\":53085.0174,\"localCurrency\":\"JPY\"&#125;id:26a06bf0-91a7-4d2f-b15a-f666e072716bdata:&#123;\"id\":\"26a06bf0-91a7-4d2f-b15a-f666e072716b\",\"name\":\"J7G766jO0\",\"createdTime\":\"2020-10-05T14:32:43.267724\",\"localPrice\":62969.8410,\"localCurrency\":\"JPY\"&#125;id:110c91ae-41b2-4223-bf33-3759c4f4dc52data:&#123;\"id\":\"110c91ae-41b2-4223-bf33-3759c4f4dc52\",\"name\":\"vlULf6xJ8\",\"createdTime\":\"2020-10-05T14:32:45.268531\",\"localPrice\":53305.5013,\"localCurrency\":\"JPY\"&#125;id:fb014f7e-3709-4223-85a2-6b4b6b6927b3data:&#123;\"id\":\"fb014f7e-3709-4223-85a2-6b4b6b6927b3\",\"name\":\"LpoMwa\",\"createdTime\":\"2020-10-05T14:32:48.271629\",\"localPrice\":75403.9377,\"localCurrency\":\"JPY\"&#125;...... 总结本文只是做了一个Spring + Kotlin的初步整合应用，并少量涉及了Spring针对Kotlin所做的一些定制和优化。从这些简单的示例中，我们仍然能够感受到Kotlin语言的强大表现力和独特的魅力。即使不去使用DSL等稍微高级的特性，Kotlin仍然表现的足够简洁与高效。Spring与Kotlin的初次相见就已擦出火花，相信在未来，Spring与Kotlin还会迸射出更加绮丽的色彩。 本文的源代码已放置在Github，欢迎大家一起讨论。谢谢！","tags":[{"name":"spring","slug":"spring","permalink":"https://danielpf.me/tags/spring/"},{"name":"kotlin","slug":"kotlin","permalink":"https://danielpf.me/tags/kotlin/"},{"name":"reactive","slug":"reactive","permalink":"https://danielpf.me/tags/reactive/"}]},{"title":"小论Spring中@Bean的Lite Mode","date":"2020-08-29T14:19:22.000Z","path":"2020/08/29/spring-bean-lite-mode/","text":"@Bean注解在现代化Spring应用中得到了广泛的应用，在大多数场景下，@Bean是配合@Configuration注解一起使用的，但这并不意味着@Bean必须配合@Configuration使用，反之，它可以与@Service、@Component等Bean声明注解一起使用，这种用法与配合@Configuration使用有什么区别呢？什么是@Bean的Lite Mode呢？本文将给出答案。 概念当@Bean定义在@Component等Bean声明注解内或POJO对象内部时称之为Lite Mode，反之，定义在@Configuration对象内部时称之为Full Mode。 Lite Mode定义 以上定义概括于@Bean的API文档以及Spring Framework的官方文档，为方便大家理解，下面我们通过一个例子来详细说明。 举例这里展示一个非常典型Lite Mode场景，并包含内部Bean依赖(inter-bean dependencies)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Slf4j@Servicepublic class LiteConfig &#123; static class LiteService &#123; static AtomicLong COUNTER = new AtomicLong(); LiteService() &#123; log.info(\"creating...\"); COUNTER.incrementAndGet(); &#125; @PostConstruct void init() &#123; log.info(\"initializing...\"); &#125; void doSomething() &#123; log.info(\"doing...\"); &#125; &#125; @Bean LiteService liteService() &#123; return new LiteService(); &#125; @Bean @Order(0) public CommandLineRunner withDependency(LiteService liteService) &#123; return args -&gt; &#123; log.info(\"running with dependency\"); liteService.doSomething(); &#125;; &#125; @Bean @Order(1) public CommandLineRunner withInterReference() &#123; return args -&gt; &#123; log.info(\"running with InterReference\"); this.liteService().doSomething(); &#125;; &#125; @Bean @Order(100) public CommandLineRunner showCounter() &#123; return args -&gt; log.info(\"total instance count: &#123;&#125;\", LiteService.COUNTER.get()); &#125;&#125; 简要解释一下， 定义了一个LiteConfig类，但注解为Service，按照定义，其内部定义的@Bean的行为都会处在Lite Mode下； LiteService是一个简单的类，包含了一个构造方法，一个初始化方法(init)，一个具体执行业务逻辑的方法(doSomething)，除日志输出外，构造方法会记录创建实例的个数； 通过@Bean创建一个LiteService的Bean； LiteServiceBean会被接下来的两个CommandLineRunnerBean依赖，依赖的方式不同，withDependency通过方法参数得到依赖，而withInterReference通过内部方法调用得到依赖； 最后一个showCounter用于打印在以上代码执行后，总共创建的LiteService实例的个数。 让我们执行这段代码并查看输出，这里将略去不相关部分， 123456789Root WebApplicationContext: initialization completed in 1290 mscreating...initializing...running with dependencydoing...running with InterReferencecreating...doing...total instance count: 2 从运行结果上，我们不难看出， Spring容器初始化完成之后，liteService()方法被Spring执行，创建了一个LiteService的Bean，并回调了init方法； 接下来withDependency的CommandLineRunner运行，liteService作为依赖被传入，并调用了doSomething方法； 接下来withInterReference的CommandLineRunner运行，通过调用liteService()方法来获取依赖，这时liteService()方法本体又被执行了一遍，并且没有回调init方法； 接下来showCounter的CommandLineRunner运行，打印了LiteService实例的总数，共2个。 具体原因，我们稍后解释，这里我们先吧@Service注解换成@Configuration，看会发生什么， 12345678Root WebApplicationContext: initialization completed in 553 mscreating...initializing...running with dependencydoing...running with InterReferencedoing...total instance count: 1 比较之前的运行结果，我们发现， 与之前相同：Spring容器初始化完成之后，liteService()方法被Spring执行，创建了一个LiteService的Bean，并回调了init方法； 与之前相同：接下来withDependency的CommandLineRunner运行，liteService作为依赖被传入，并调用了doSomething方法； 与之前不同：接下来withInterReference的CommandLineRunner运行，通过调用liteService()方法来获取依赖，没有重新执行本体，直接调用了doSomething方法； 与之前不同：接下来showCounter的CommandLineRunner运行，打印了LiteService实例的总数，只有1个。 综上所述，两次运行结果的差异表现在当使用inter-bean references获取内部依赖时的行为不同，Lite Mode下，内部方法调用就是纯粹的执行了内部方法的逻辑，而在Full Mode下，内部方法调用被Spring拦截且直接返回了已经创建好的Bean，并没有重新执行内部方法的逻辑。 揭秘官方文档有大段的论述来解释Lite Mode与Full Mode，原文稍微有一些晦涩，这里我提炼一下官方文档中关于Lite Mode与Full Mode的异同， 相同点： Lite Mode定义下的Bean本质上与Full Mode定义下的Bean没有本质区别，都可以被其他Bean依赖； Bean容器仍然会管理Lite Mode定义下的Bean的生命周期，@PostConstruct、@PreDestroy等注解依然生效； 不同点： Lite Mode无法兼容内部Bean依赖(inter-bean dependencies)，究其本质，在Full Mode下，Spring会使用类似CGLIB proxy来拦截所有的方法调用，如果发现内部方法调用是为了获取内部Bean依赖(inter-bean dependencies)，那么Spring将直接返回这个Bean。 从这些异同点我们可以看出，Spring的设计者对于使用类似CGLIB proxy来拦截所有的方法这类操作还是比较慎重的，所以不惜用Full Mode和Lite Mode加以区分，也为使用者提供了精确控制与选择的机会，即使绝大部分使用者一般都会选择使用Full Mode。 实践有同学可能会问，如上面的例子所示，withDependency的CommandLineRunner是通过方法参数来获取依赖的，只不过这个依赖是在同一个类里面由另外一个@Bean方法定义的内部Bean依赖，这个也是Spring推荐的方式，那么不就可以避免通过内部方法调用来获取依赖了吗？ 一般情况下，答案是肯定的，但也有例外情况，假设我们不能自定义一个使用依赖的方法的参数呢？这种场景存在吗？看下面的例子， 1234567891011121314151617181920212223242526272829@Configurationpublic class WebMvcConfig extends WebMvcConfigurationSupport &#123; public static class DummyInterceptor implements HandlerInterceptor &#123; @PostConstruct public void init() &#123; log.info(\"initializing dummy interceptor...\"); &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //handling logic return true; &#125; &#125; @Bean public DummyInterceptor dummyInterceptor() &#123; return new DummyInterceptor(); &#125; @Override protected void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(this.dummyInterceptor()).addPathPatterns(\"/**\"); super.addInterceptors(registry); &#125;&#125; 在Spring Boot应用中，我们经常会通过扩展WebMvcConfigurationSupport来自定义一些MVC相关的设置，上面的例子就是在自定义拦截器，而拦截器恰好是在当前类里面通过@Bean创建的一个Bean，而addInterceptors方法却是要覆写父类的，无法通过修改参数列表来获取依赖，只能通过调用内部方法来获取，这时Full Mode就有用武之地了，通过调用内部方法，就会得到一个完整的Spring容器管理的拦截器Bean。这样的场景在扩展Spring的各种Config里很常见，例如Spring Security、Spring Data Couchbase等。 总结在Spring体系中，@Bean是一个再常用不过的注解，但Lite Mode与Full Mode并不被人所熟知。当我们肆意使用@Bean定义着Bean，通过方法参数传递传递着依赖时，我们并不清楚Spring的设计者有多少设计上的考量以及Spring的开发者通过哪些手段和技巧实现了设计者的理念。表面上看，这些无伤大雅，也无关紧要，甚至作为细节，使用者也无需关心，我随便baidu了一下spring @bean lite mode这几个关键字，发现为数不多的文章里，大部分是机器翻译了Spring的官方文档，幸甚幸甚，至少还有人去看这部分的文档。 分享这个小技巧，并不是为了炫技，因为这本身也没有什么高深的，我甚至都没有贴一行Spring的源代码，我也不想去找，因为我觉得Spring官方文档上的论述就已经足够好了，不管我们是否关心，它都在那里。 后记前面提到，Lite Mode是可以用在POJO对象里的，那会是怎样的行为呢？有兴趣的朋友可以自己试试看。","tags":[{"name":"spring","slug":"spring","permalink":"https://danielpf.me/tags/spring/"}]},{"title":"再论Spring依赖注入","date":"2020-06-12T13:11:31.000Z","path":"2020/06/12/spring-dependency-injection-rethinking/","text":"依赖注入(Dependency Injection)是Spring Framework最核心的概念之一，通常来说，依赖注入主要分成构造注入(Constructor-based Dependency Injection)与setter注入(Setter-based Dependency Injection)两种类型，本文会结合Spring Framkework的发展以及项目中的具体应用，在封装性(Encapsulation)、不可变性(Immutability)、安全性(Security)以及循环依赖性(Circular Dependencies)等方面来重新探讨这两种依赖注入方式，进而总结出在“新时代”的背景下，如何适当地选择。 谨以此文献给在code review中备受打击的小G同学。。。 篇首语 细说分类首先说setter注入，这是最常见也是最老牌的一种依赖注入方式，套用Spring官方文档的例子，这种注入方式的特点是先创建实例，再反射调用setter方法注入依赖， 123456789101112public class SimpleMovieLister &#123; // the SimpleMovieLister has a dependency on the MovieFinder private MovieFinder movieFinder; // a setter method so that the Spring container can inject a MovieFinder public void setMovieFinder(MovieFinder movieFinder) &#123; this.movieFinder = movieFinder; &#125; // business logic that actually uses the injected MovieFinder is omitted...&#125; 而在@Autowired注解的帮助下，setter注入也衍生出了最简化的形式，以上代码直接可以写作下面的形式，我们姑且叫它私有变量注入，这种注入方式的特点是，先创建实例，再反射修改私有变量注入依赖，时至今日，相信很多coder还是非常乐于使用这种依赖注入方式， 123456public class SimpleMovieLister &#123; @Autowired private MovieFinder movieFinder;&#125; 接下来再说构造注入，这种注入方式更加直接，其特点是,创建实例与注入依赖同时进行，都是通过反射调用构造方法完成， 123456789101112public class SimpleMovieLister &#123; // the SimpleMovieLister has a dependency on a MovieFinder private MovieFinder movieFinder; // a constructor so that the Spring container can inject a MovieFinder public SimpleMovieLister(MovieFinder movieFinder) &#123; this.movieFinder = movieFinder; &#125; // business logic that actually uses the injected MovieFinder is omitted...&#125; 这里再介绍一种进阶版，采用lombok + private finaal的构造注入才是最常见的写法，我们接下来讨论的构造注入，如不特殊说明，都是指的这种方式， 12345678910111213@RequiredArgsConstructorpublic class SimpleMovieLister &#123; // the SimpleMovieLister has a dependency on a MovieFinder private final MovieFinder movieFinder; // lombok will help generate this method during compiling time //public SimpleMovieLister(MovieFinder movieFinder) &#123; //this.movieFinder = movieFinder; //&#125; // business logic that actually uses the injected MovieFinder is omitted...&#125; 随着Java-based Container Configuration越来越流行，构造注入也有了广义上的版本，我们姑且叫它方法参数注入，与普通构造注入不同的是，依赖是作为反射调用bean创建方法的参数(args)注入，而对象实例化过程，是由在方法内部编程实现，而bean的依赖可能是构造注入，也可能是setter注入，看下面的例子， 1234567891011121314@Configurationpublic class MovieListerConfig &#123; @Bean public SimpleMovieLister simpleMovieLister(MovieFinder movieFinder) &#123; // implemented as constructor-based injection return new SimpleMovieLister(movieFinder); // it can be also implemented as setter-based injection // SimpleMovieLister lister = new SimpleMovieLister(); // lister.setMovieFinder(movieFinder); // return lister; &#125;&#125; 特殊依赖这里还需要举例说明两种特殊的依赖。 第一种很常见，其依赖不是其他的bean，而是一个外部的值，还以上面的代码为例， 123456789public class SimpleMovieLister &#123; @Autowired private MovieFinder movieFinder; @Value(\"$&#123;app.movie_lister.max_size:100&#125;\") private Integer maxSize;&#125; 另外一种比较特殊，但有可能在不知不觉中还是接触到了，这个就是循环依赖， 12345678910111213public class ServiceA &#123; @Autowired private ServiceB serviceB;&#125;public class ServiceB &#123; @Autowired private ServiceA serviceA;&#125; 这个列子只是最简单的循环依赖，还有更复杂一些的情况，例如ServiceA -&gt; ServiceB -&gt; ServiceC -&gt; ServiceA，这里不再赘述。 对比我们用一个表格来对比这些注入方式， 对比项 setter注入 私有变量注入 构造注入(private final) 保证封装性？ Yes No Yes 保证不可变性？ No No Yes 保证安全性？ No No Yes 允许循环依赖？ Yes Yes No 下面详细解释一下表格内容。 封装性(Encapsulation)是OOP的三大特性之一，这里我们不做展开说明，而setter注入与构造注入为何没有破坏封装性，也非常容易理解，那就是Spring是通过反射私有变量访问器(setter方法或构造方法)来完成依赖注入的，完全遵守了封装性的准则。那么问题来了，为什么私有变量注入破坏了封装性？ 私有变量注入本质上是通过反射修改私有(private)变量值来完成依赖注入的，完全没有通过私有变量访问器，换句话说，一个私有的变量平白无故地就被修改了值。 为什么“私有变量注入”破坏了封装性？ 乍一看，即使封装性被破坏，也没有什么大不了的，从结果上看，未经私有变量访问器修改的值也是符合预期的，但事实上一旦封装性被破坏，不可变性(Immutability)亦不能保证。不可变性(Immutability)也是软件OOP里一个非常重要设计理念，这里我们仍不做展开。但依照上面的表格所示，即使封装性可以保证，仍不能保证一个对象的不可变性。 啰嗦了这么多，无论封装性也好，不可变性也罢，其实都是为了保重代码在处理依赖注入时的安全性(Security)。这里的安全性(Security)是一个相对狭义的概念，其含义可以概括为一点，不可变的依赖，才可能是无害的依赖。说起来可能很抽象，下面用两个逆向场景具体说明， setter作为访问器，在开放给Spring的同时，也开发给了其他代码。无论善意或恶意，只需要重新调用一下setXXX方法，哪怕传入一个null值，其影响也足够致命。 为什么“setter注入”不安全？ 与setter注入类似，虽然私有变量注入并没有提供一个setter作为访问器，但通过反射，仍然可以直接修改私有变量的值，在运行时改变依赖。 为什么“私有变量注入”不安全？ 以上两个场景概括起来，就是在说明，存在这样或那样的可能性，在运行时(runtime)阶段，依赖是有可能被有意或无意修改，从而导致程序的行为不正确，甚至产生灾难性后果。基于以上分析，也很容易推导出保证运行时安全性的手段，那就是构造注入且私有变量为final, 简而言之，Java语言在语义(semantic)上保证final是不可修改的，所以不会在运行时(runtime)被修改，即使通过反射亦不可能。 为什么“private final”安全？ 结论技术本无对错，只看是否适用于不同的场景，而不同的技术，在不同的历史时期和时代背景下，会进化、发展、演变出不同的方式、流派、体系，Spring Framework亦是如此。 在Spring 2.5.x时代，依赖注入与控制反转方兴未艾，广大Java EE的开发人员，还在被EJB折腾的七窍生烟之时，Spring所倡导的这些理念，让从业者有久旱逢甘霖之快感，而受限于当时的技术理念与潮流，仍使用XML作为bean相互依赖的组织媒介，使用setter注入便是“多快好省”的不二法门。 随着时间的推移，人们对依赖注入、控制反转理解和实践的逐渐深入，Spring 3.x也呼之欲出。开发者也越发体会到，bean与bean之间的依赖关系，在绝大多数场景下是内联的，是自然的，甚至是与生俱来的，无论你是否用XML等配置方式去描述它，这些bean之间的依赖关系，都在那里，且相对稳定，几乎不会被修改。于是，在这个理念的指导下，才有了bean的自动装配(Autowired)，才有了后来Annotation-based Container Configuration，曾经漫山遍野的XML也淹没于扑面而来的@Autowired注解之中，而私有变量注入注入更是让人高潮迭起，如痴如醉，被传统Java EE思想钳制多年的思想也随之解放，以少量的XML加以大量的私有变量注入也蔚然成风，仿佛构造方法和setter都成了明日黄花，不合时宜。 一个好的技术框架，其生命力往往取决于设计者的思想境界。当劳苦大众们在为使用私有变量注入大幅提高生产力而弹冠相庆时，Spring团队却没有停下审视和思考的脚步。于是更加极至的Java-based Container Configuration也随之诞生，并在Spring 5.x后受到Spring官方推崇。有人说Java-based Container是历史的倒退，是Java EE糟粕的复辟，现在看来，不得不佩服Spring设计者独到的眼光和正派的价值观，其终极目标，仍然是以不可变性与安全性在程序设计领域重要的作用为导向的，尤其在以线程模型为程序基本运行模型的JVM语言里更是如此，所以依赖注入方式在经过无数的私有变量注入滥用，在肯定bean之间的自然依赖关系的条件下，回归到了private final变量 + 构造注入的方式，继而出现了使用lombok来简化唯一构造方法的终极写法。 拥抱变化，拥抱发展，这才是Spring Framework经久不衰的主要原因。而作为终端用户的我们，除了与时俱进，更要尊重技术发展的潮流，既不能用旧时代的想法和思路来处理新时代问题，也不能用新时代的视角和手段来否定旧时代技术，唯有如此，才是技术人员应有的素质和觉悟。 让我们回归本篇文章的讨论，在新时代的背景下，如何选择依赖注入方式呢？归纳起来，也就是下面几点， 优先采用private final变量 + 构造注入来注入依赖； 在没有其他值(依赖)需要注入时，可以考虑用lombok的@RequiredArgsConstructor来简化代码； 原则上应避免循环依赖，如果实在无法避免，可以适度使用setter注入，但仍应该避免使用私有变量注入； 在Unit Test等场景下，仍然可以使用私有变量注入来简化代码。","tags":[{"name":"spring","slug":"spring","permalink":"https://danielpf.me/tags/spring/"}]},{"title":"茴字的N种写法","date":"2020-05-03T13:55:48.000Z","path":"2020/05/03/n-ways-of-writing-word-hui/","text":"在鲁迅的名篇《孔乙己》中，有这样一个桥段，孔乙己问作者是否知道茴香豆的“茴”字，有四种写法，用于讽刺孔乙己这类落魄文人的迂腐。我们在coding时，为实现某一逻辑，也会存在各种各样的方案，而每种方案的背后，除了有各自的特点之外，也或多或少与给出这些方案的人的技能、经历、思考方式有关，本文试图以亲身经历的一个小故事，来探究编程领域内茴字N种写法背后的故事。 起因一次代码Review的过程中，看到了类似下面的代码 123456789public OrderApiResponse getOrder(String orderId) &#123; var headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); headers.setAccept(Collections.singletonList(MediaType.APPLICATION_JSON)); var request = new HttpEntity&lt;&gt;(Collections.singletonMap(\"orderId\", orderId), headers); var response = restTemplate.exchange(orderApiUri, HttpMethod.POST, request, String.class); return JSON.parseObject(response.getBody(), OrderApiResponse.class);&#125; 放眼望去，感觉没什么不对；仔细端详，又感觉哪里不对….为什么要用String作为response的参数化类型呢？另外这个JSON.parseObject也不是Spring Framework内置的Jackson啊，仔细一看原来是我天朝上国的fastjson，为什么要放弃内置的Json方案而再引入一个第三方的呢？ 赶紧找来开发人员小G请教原委， Order API Response的属性名是以大写字母开头的，Jackson默认不能处理，fastjson默认可以处理，所以引入了fastjson并以String类型接收响应。 小G的回答 Hmmm，貌似很有道理的样子，但仔细推敲起来，至少还有其他问题，于是我回复道， 假设Order API返回10000个属性，我们只用10个，使用String全部接收响应，岂不是很浪费？性能是不是也不高？ 假设使用fastjson不可避免，那么是否有更好的解决方案呢？ 我的回复 开发人员G于是进入了冥思苦想状，而我的思绪也逐渐模糊，从fastjson转向了RestTemplate。 第二种写法无论使用Spring MVC来做为Server端，还是使用RestTemplate来做为Clinet端，Spring Framework都是在使用HttpMessageConverter来处理http消息。 Spring Framework内置了很多Http Message Converters，而MappingJackson2HttpMessageConverter就是内置使用Jackson来处理Json的Converter，假设我们要使用fastjson来替换Jackson，最好的办法是直接在替换掉MappingJackson2HttpMessageConverter，这样在使用RestTemplate来请求API时，不需要手动处理response的反序列化，本来，序列化方式也应该对客户端代码是透明的。那么问题来了，如何替换掉MappingJackson2HttpMessageConverter呢？来，动手吧。 12345678910111213141516171819public class OrderApiClient &#123; private final RestTemplate restTemplate; public RestTemplate restTemplate(RestTemplateBuilder restTemplateBuilder) &#123; var converter = new FastJsonHttpMessageConverter(); this.restTemplate = restTemplateBuilder.build(); var messageConverters = this.restTemplate.getMessageConverters(); var converters = messageConverters.stream() .filter(item -&gt; !(item instanceof MappingJackson2HttpMessageConverter)) .collect(Collectors.toList()); converters.add(converter); this.restTemplate.setMessageConverters(converters); &#125; public OrderApiResponse getOrder(String orderId) &#123; //... &#125;&#125; Seems better now. 开发人员G对我的这个方案很满意，且慢，我还有问题呢！ 既然Spring已经内置了Jackson来处理Json，我们为什么要画蛇添足地引入另外一种Json处理包呢？ 既然fastjson能做到，凭什么Jackson做不到呢？ 我的新问题 路漫漫其修远兮，吾将上下而求索。 第三种写法在我苦苦求索不得要领之时，小R兴冲冲跑过来说道， Jackson有对应的MapperFeature来支持兼容大写字母开头的属性名； 我们使用的是Spring Boot，可以直接使用properties来设置该属性，不需要额外写代码； 小R的回复 综合小R的回复，我们只需要在application.properties文件里，加上这么一句就好啦， 1spring.jackson.mapper.accept_case_insensitive_properties=true So Easy, 难道不是吗？可是敏而好学，不耻下问的我，又有新问题了， 如果兼容非Java Bean规范的属性名，想必要付出额外的性能代价吧？ 在我们的应用中，有很多外部API调用的场景都使用到了RestTemplate，但并不是所有的这些场景都需要兼容首字母大写的属性名吧？ 配置在application.properties中的mapper_feature应该是全局设置，对所有的RestTemplate都起效吧，那岂不是说不需要兼容首字母大写的API调用在使用RestTemplate时也需要承担性能下降的代价？ 我的新问题 显然，还得继续求索啊。 第四种写法为了不使其他使用RestTemplate的API Client收到全局配置的影响，那么就不能在全局配置，配置应该发生在个体之上。在这个思路的只因下，小R在OrderApiClient自己的RestTemplate上下手了， 123456789101112131415161718192021222324public class OrderApiClient &#123; private final RestTemplate restTemplate; public RestTemplate restTemplate(RestTemplateBuilder restTemplateBuilder) &#123; this.restTemplate = restTemplateBuilder.build(); var messageConverter = this.restTemplate.getMessageConverters() .stream() .filter(MappingJackson2HttpMessageConverter.class::isInstance) .map(MappingJackson2HttpMessageConverter.class::cast) .findFirst() .orElseThrow(() -&gt; new RuntimeException(\"MappingJackson2HttpMessageConverter not found\")); messageConverter.getObjectMapper().configure(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES, true); &#125; public OrderApiResponse getOrder(String orderId) &#123; //... &#125;&#125; 很好，所有的问题都解决了，需求实现了，性能还不错，更没有污染全局，小R，V5！然而，既然已经走到了这里，还能更进一步吗？ 更进一步正如上面所说，该做到的其实都已经做到了，无以复加了。可是患有强迫症的我，仍然觉得代码在结构和写法上仍然还有可调整的空间， 我们真的需要那个RuntimeException吗？ 基于目前的代码，所有的Converters里真的会没有找到MappingJackson2HttpMessageConverter？ 如果以上两个问题的答案是No，那么代码是否能写的更优雅呢？ 我的新问题 这次不劳烦小G和小R动手了，我来亲手把它写出来吧，更进一步之后大概是这样子的， 1234567891011121314151617181920212223public class OrderApiClient &#123; private final RestTemplate restTemplate; public RestTemplate restTemplate(RestTemplateBuilder restTemplateBuilder) &#123; this.restTemplate = restTemplateBuilder.build(); this.restTemplate.getMessageConverters() .stream() .filter(MappingJackson2HttpMessageConverter.class::isInstance) .map(MappingJackson2HttpMessageConverter.class::cast) .findFirst() .map(MappingJackson2HttpMessageConverter::getObjectMapper) .ifPresent(objectMapper -&gt; objectMapper.configure(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES,true)); &#125; public OrderApiResponse getOrder(String orderId) &#123; //... &#125;&#125; 好了，终于没有然后了。 退而思之让我们复盘一下整个故事的发展过程， 引入fastjson并单独使用JSON.parseObject来处理非标准变量名； 使用fastjson的FastJsonHttpMessageConverter来替换自带的MappingJackson2HttpMessageConverter； 干掉fastjson，在application.properties中配置全局的mapper_feature来适应非标准变量名； 直接修改OrderApiClient自己的RestTemplate的mapper_feature来适应非标准变量名，并避免污染全局； 让代码变得更简洁、优雅。 从以上故事的发展过程，我们又可以总结出代码实现的不同等级， 实现了功能，但性能一般； 实现了功能，性能尚可，但引入了不必要的依赖； 实现了功能，性能尚可，但副作用较大，污染了全局； 实现了功能，性能不错，无污染，无副作用，代码略显冗余，或可读性差； 实现了功能，性能不错，无污染，无副作用，代码简洁优雅、易读易懂。 我们在做代码实现时，相信我们无一例外，都是奔着最高标准的第五点去的，没人从主观上就想写烂代码。但由于每个人的技能、经历、思考方式不同，写出的代码也自然不同，其质量也会大概率地分布在这五个等级内。我不能要求每个人写出的每行代码都是最高等级的，但我希望每行代码都能更趋近于最高标准。 为你们总结一下吧，小G，小R，新时代的我们，应该如何去写高质量的代码 首先要技术过硬，知其然亦要知其所以然； 要有全局观念和大局意识，从小处着手但从大处着眼； 多写亦要多想，学而不思则罔，思而不学则殆； 最后一点，也是最为重要的一点，对代码，一定要保留一份敬畏之心，一行代码写下去，即便不关乎个人生死，也会关乎项目存亡，不可不慎，不可不察。 我的总结 参考资料 springboot2集成RestTemplate并使用fastjson序列化对象 springboot之jackson的两种配置方式 Make JSON payload fields case insensitive when mapping to Java Object in REST API developed using SpringBoot How can we configure the internal Jackson mapper when using RestTemplate?","tags":[{"name":"spring","slug":"spring","permalink":"https://danielpf.me/tags/spring/"},{"name":"resttemplate","slug":"resttemplate","permalink":"https://danielpf.me/tags/resttemplate/"},{"name":"jackson","slug":"jackson","permalink":"https://danielpf.me/tags/jackson/"},{"name":"fastjson","slug":"fastjson","permalink":"https://danielpf.me/tags/fastjson/"}]},{"title":"Reactor技巧4则","date":"2020-05-03T04:38:29.000Z","path":"2020/05/03/4-reactor-tips/","text":"本篇文章旨在介绍一些不常用但又非常有用的Reactor Operator。 Tip 1: filterWhen与Java内置的Stream API类似，Reactor也提供了fitler操作符，用于按照某些条件来过滤元素，但该操作符并不能很好处理返回值是Publisher&lt;Boolean&gt;的Predicate，例如希望判断某个key是否在Redis中存在，且使用Reactive的形式访问Redis，类似下面的code， 123456public Mono&lt;Boolean&gt; keyExists(String key) &#123; ReactiveStringRedisTemplate template = //injected by container; return template.hasKey(key);&#125; 这时，filterWhen操作符就非常有用，其方法签名为： 1public final Flux&lt;T&gt; filterWhen(Function&lt;? super T,? extends Publisher&lt;Boolean&gt;&gt; asyncPredicate) 我们可以看到用于过滤的函数由一个简单的Predicate变成了一个返回值为Publisher&lt;Boolean&gt;的Function，对于上面的判断，处理起来就很自然了， 123456ReactiveStringRedisTemplate template = //injected by container;Flux.just(\"key1\", \"key2\", \"key3\") .map(key -&gt; \"key_prefix:\" + key) .filterWhen(template::hasKey) .subscribe(); 以下几点需要注意： 当Publisher的元素为empty时，等同于false; 当Publisher为Flux时，只有第一个元素参与比较，其他元素将被忽略; Tip 2: expand我们在日常处理各种程序逻辑时，经常会处理分页或者递归的数据，此类数据在Imperative编程模式下很容易处理，那么如何在Reactove编程模式下处理呢？其实Reactor为我们提供了expand方法，可以方便地处理类似数据，其方法签名如下， 1public final Flux&lt;T&gt; expand(Function&lt;? super T,? extends Publisher&lt;? extends T&gt;&gt; expander) 我们只需要提供一个具备分页或者递归边界的Function就可以了，expand会自动帮我们把数据整理到Flux中。假设我们有这样的一个方法，用于递归(分页可以理解为递归的一种特殊形式)地加载数据， 12345678private Mono&lt;String&gt; composeRecursively(String key) &#123; //A -&gt; AA -&gt; AAA if (key.length() &gt;= 3) &#123; return Mono.empty(); &#125; else &#123; return Mono.just(key + key.charAt(0)); &#125;&#125; 注意，以上代码中，’key.length() &gt;= 3’就是所谓的递归边界。当使用expand方法按照上面的逻辑处理&quot;A&quot;, &quot;B&quot;, &quot;C&quot;数据时， 123Flux.just(\"A\", \"B\", \"C\") .expand(this::composeRecursively) .subscribe(log::info); 输出结果为， 123456789ABCAABBCCAAABBBCCC 我们都知道，递归的本质是对树的遍历，从上面的执行结果，我们可以看到，expand是按照广度优先来遍历树的，那么如果我们的程序逻辑是顺序敏感的，且希望使用深度优先来遍历呢？Reactor为我们提供了expandDeep方法，其防方法名如下， 1public final Flux&lt;T&gt; expandDeep(Function&lt;? super T,? extends Publisher&lt;? extends T&gt;&gt; expander) 当我们使用该方法处理上面的’composeRecursively’数据时， 123Flux.just(\"A\", \"B\", \"C\") .expandDeep(this::composeRecursively) .subscribe(log::info); 输出结果变为， 123456789AAAAAABBBBBBCCCCCC 由此可见，深度优先遍历的目的就达到了。 Tip 3: transform &amp; astransform和as都属于Mutualization(字面含义为“相互化”)操作，这类操作与map、flatMap等最大的区别为，前者的操作对象是Publisher中的元素，而后者操作的是Publisher的本身。首先我们看一下transform的方法签名， 1public final &lt;V&gt; Flux&lt;V&gt; transform(Function&lt;? super Flux&lt;T&gt;,? extends Publisher&lt;V&gt;&gt; transformer) 我们可以看到作为参数的Function，其入参出参皆为Flux，而不是元素，那么我们就可以在这个Function中完成对Flux的处理或变换， 1234567Function&lt;Flux&lt;Integer&gt;, Flux&lt;String&gt;&gt; mapAndApplySchedulers = f -&gt; f.map(String::valueOf) .subscribeOn(Schedulers.boundedElastic()) .publishOn(Schedulers.parallel());Flux.just(1, 2, 3).transform(mapAndApplySchedulers).subscribe(); 由此可见，当我们需要处理的是Flux本身而不是其中的元素的时候，transform是最合适的选择。 我们再来看as，其方法签名为， 1public final &lt;P&gt; P as(Function&lt;? super Flux&lt;T&gt;,P&gt; transformer) 与transform相比，其Function输出参数由Flux变成了一个P，不再限定为Publisher，而整个函数的返回值也不再限定为Flux，这样的逻辑使得as可以作为衔接多步Publisher操作并保持方法流式调用(fluent)风格的不二选择，请看下面的例子， 12345Flux&lt;Integer&gt; i = Flux.range(1, 10) .map(i -&gt; i + 2) .map(i -&gt; i * 10);Mono&lt;String&gt; s = MathFlux.sumInt(i) .map(isum -&gt; \"sum=\" + isum); MathFlux.sumInt接收一个Flux&lt;Integer&gt;作为参数进行后续运算，多个步骤导致这种调用方式破坏了流式调用(fluent)风格，那么使用as可以解决，流式调用(fluent)风格得以保留， 12345Mono&lt;String&gt; s = Flux.range(1, 10) .map(i -&gt; i + 2) .map(i -&gt; i * 10) .as(MathFlux::sumInt) .map(isum -&gt; \"sum=\" + isum); 再看一个在Spring Webflux里经常出现的场景， 12345public Mono&lt;ServerResponse&gt; handle(ServerRequest request) &#123; var result = Flux.just(\"A\", \"B\", \"C\") .map(String::toLowerCase); return ServerResponse.ok().body(result, String.class);&#125; 以上代码中，在第一步，产生了作为response body的result，在第二步再组装成了ServerResponse，流式调用(fluent)风格遭到破坏，可以使用as处理， 123return Flux.just(\"A\", \"B\", \"C\") .map(String::toLowerCase) .as(f -&gt; ServerResponse.ok().body(f, String.class)); 当然，使用transform亦可解决问题，就是稍显冗长一些， 1234return Flux.just(\"A\", \"B\", \"C\") .map(String::toLowerCase) .transform(f -&gt; ServerResponse.ok().body(f, String.class)) .next(); 以上代码对比，在某些场景下，我们可以把as理解为transform + next的简写方式。 Tip 4: usingReactor提供及其丰富的API来创建一个Publisher，其中有很多方法用于桥接非Reactive的数据类型，之中比较有用的是fromStream，通过使用该API，可以非常容易的创建一个Publisher，由于Stream的懒运行特性，使得Stream作为imperative编程风格下的产物，却具备了先天的Reactive编程风格的适配能力。例如下面的代码， 123Flux.fromStream(Stream.of(\"A\", \"B\", \"C\")) .map(String::toLowerCase) .subscribe(); 但这里又一个陷阱，并不是所有的Stream在使用后都不需要close，很多与IO或者下层资源有关的Stream在使用后是需要显式关闭的，或者采用等效的隐式方式关闭，例如try-with-resources。有两个非常典型的这一类Stream的例子，一个是Files.lines(Path path)返回的Stream，另一个就是在String Data JPA的Repo中返回的Stream。假设我们需要从文件中读取每一行并作为Flux的源，为了保证读取文件而产生的Stream可以被正确关闭，代码上要做额外的处理，而不只是使用Flux.fromStream。 123456var lines = Files.lines(Paths.get(\"test.txt\"));Flux.fromStream(lines) .filter(s -&gt; s.length() &gt; 10) .map(String::toLowerCase) .doFinally(signalType -&gt; lines.close()) .subscribe(); 首先肯定，以上代码可以达到目的，但仍有不足之处： 破坏了流式调用(fluent)风格； 在使用副作用(side-effect)来处理Publisher外部的资源。 那么如何可以比较优雅地关闭Stream而又避免上面的两个不足呢？答案就是using，其方法签名如下， 123public static &lt;T,D&gt; Flux&lt;T&gt; using(Callable&lt;? extends D&gt; resourceSupplier, Function&lt;? super D,? extends Publisher&lt;? extends T&gt;&gt; sourceSupplier, Consumer&lt;? super D&gt; resourceCleanup) 我们可以看到，using方法包含3个参数，resourceSupplier表示一个数据源，例如产生Stream的各种方式；sourceSupplier代表一个使用该数据源产生Publisher的一个函数，例如Flux.fromStream()，最后一个resourceCleanup代表一个清理回调，可以清理由resourceSupplier产生的数据源。OK，一切水到渠成啦，用using改写文件读取的例子，如下面的代码所示， 1234Flux.using(() -&gt; Files.lines(Paths.get(\"test.txt\")), Flux::fromStream, BaseStream::close) .filter(s -&gt; s.length() &gt; 10) .map(String::toLowerCase) .subscribe(); 如代码所以，流式调用(fluent)风格得以保留，也避免了副作用(side-effect)。using还有更复杂的方式，usingWhen，请自行参考文档。 总结Reactor所提供的API及其丰富，如套用Java StreamAPI的部分理念，对于大部分API，相对容易理解，而真正难于掌握的，是在Reactive编程风格的大前提下，产生的Reactive独有的方法及其操作风格。本篇文章只是介绍了在日常的使用过程中，沉淀下来的几个例子，虽不常用，但在某些场景下，却非常有用，甚至不容易被其他方式替代。相信在项目的驱动下，在使用Reactive编程风格及Reactor API的过程中，还会遇到新的问题和挑战，如有积累，会再找机会与大家分享。 参考资料 compose() vs. transform() vs. as() vs. map() in Flux and Mono Reactor - Using transform Operation File Reading in Reactor","tags":[{"name":"reactive","slug":"reactive","permalink":"https://danielpf.me/tags/reactive/"},{"name":"reactor","slug":"reactor","permalink":"https://danielpf.me/tags/reactor/"}]},{"title":"简单实现微软Teams的logback appender","date":"2020-04-08T12:15:15.000Z","path":"2020/04/08/logback-msteams-appender-plus/","text":"不得不承认，微软的Teams聊天软件借(chao)鉴(xi)了很多Slack的理念，凭借其庞大的用户群体以及产品生态优势，使Teams在短时间内得以快速发展和推广。与其他消息工具类似，Teams也提供了webhook，使用它可以很容易地拓展Teams的功能，使其不仅限于一个聊天软件，更可以使其变成一个消息门户。今天我们就实现一个logback appender，使Teams可以显示应用程序的报警通知。 Webhook在Teams中Connectors是用来与外部应用程序沟通的重要媒介，而Incoming webhooks就是一种特殊的Connector， 它本质上就是一个唯一的URL，可以通过向这个URL来post一组JSON信息，来达到与Teams沟通协作的目的。关于Teams中Connector与webhook的更多介绍，可以参考这里。 在开始向Teams发送日志之前，我们应该准备好webhook，创建webhook很简单，大概就是下面的几个步骤， 首先在希望展示log信息的聊天群组中新建一个channel; 配置这个channel的Connectors，添加一个Incoming Webhook; 可以给这个webhook配置一个独特的头像，也可以使用默认; 拷贝生成的webhook URL备用。 关于创建webhook的详细步骤，可以参考这里。 Message Card发送至Teams的JSON结构要遵守office-365-connector-card的约束，这里我们只采用Cards中相对简单的Message Card来作为消息的载体，其JSON结构类似于， 1234567&#123; \"@type\": \"MessageCard\", \"@context\": \"http://schema.org/extensions\", \"themeColor\": \"0076D7\", \"title\": \"Larry Bryant created a new task\", \"text\": \"Let's do it\"&#125; 借助于Lombok与Jackson，MessageCard 的实现非常简单， 1234567891011121314151617@Data@Builderpublic class MessageCard &#123; @JsonProperty(\"@type\") private final String type = \"MessageCard\"; @JsonProperty(\"@context\") private final String context = \"http://schema.org/extensions\"; private String title; private String text; private String themeColor;&#125; Http客户端前面已经讲到，Teams中的消息是来自于POST到webhook的MessageCard的JSON，所以挑选一个合适的http客户端就非常的重要，我们希望这个http客户端能够具备以下特性： 高性能（不解释）; 少依赖（我们自然不希望一个logback appender还有一大堆的依赖）; 全特性（至少能够支持配置代理等特性，毕竟发送日志的应用不一定能够直接请求到webhook）; 按照以上的要求，这里我们选择OkHttp，以上3点都可以满足。下面的代码段展示如何根据配置参数构建一个http client，支持以下属性： 连接超时; 读写超时; 代理和代理凭据; 123456789101112131415161718192021222324252627282930private final OkHttpClient okHttpClient;public MsTeamsAppender() &#123; final OkHttpClient.Builder builder = new OkHttpClient.Builder(); // Timeout Setting builder.connectTimeout(connectTimeout, TimeUnit.MILLISECONDS) .writeTimeout(writeTimeout, TimeUnit.MILLISECONDS) .readTimeout(readTimeout, TimeUnit.MILLISECONDS); // Proxy Setting if (Objects.nonNull(proxyHost) &amp;&amp; Objects.nonNull(proxyPassword)) &#123; builder.proxy(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(proxyHost, proxyPort))); &#125; // Proxy Authentication Setting if (Objects.nonNull(proxyUsername) &amp;&amp; Objects.nonNull(proxyPassword)) &#123; final Authenticator proxyAuthenticator = (route, response) -&gt; &#123; String credential = Credentials.basic(proxyUsername, proxyPassword); return response.request().newBuilder() .header(\"Proxy-Authorization\", credential) .build(); &#125;; builder.proxyAuthenticator(proxyAuthenticator); &#125; this.okHttpClient = builder.build();&#125; 以上代码中的 connectTimeout、writeTimeout、readTimeout、proxyHost、proxyPort、proxyUsername、proxyPassword 均来自于logback的配置文件。 消息内容的结构与样式在Teams中显示系统异常信息，其主要目的还是为了提醒或者是报警，而不是用Teams来替代系统日志。当出现异常时，我们可以通过Teams的信息快速了解到报错的摘要，进而判断紧急程度，如果需要采取进一步的分析，仍然需要通过其他技术手段来查看详细日志，例如日志文件或者ELK。无论从业务需求或是性能需求看，发送到Teams的消息应该尽可能的简单高效，一目了然。基于以上目的，我们用下面的结构与样式来表现一个消息的内容， title prefix(可选), 标题前缀会自动被[]包围，用来展示Server或者Appliation的名称，当然也可以直接指定环境profiel，例如staging、prod等; title body, 出错日志的message部分，能够非常直观的了解到报错的消息内容，例如log.error(&quot;error occurred when processing request&quot;, e), 那么title body就是 error occurred when processing request ; body logger name, 输出这个日志的logger，一般是一个class的全名; formatted message, 相当于Exception的名称和Error Message，假设抛出异常的代码是new IllegalStateException(&quot;OPS! You are not so good...&quot;), 那么输出的消息就是 java.lang.IllegalStateException: OPS! You are not so good…; exceptoin stack trace, 由于异常的stack trace往往都很长，这里我们会加以限制，最多打印N行，默认N=5，超出部分用 … 来代替； 基于以上定义，如果抛出一个new IllegalStateException(&quot;OPS! You are not so good...&quot;)异常且被log.error(&quot;error occurred when processing request&quot;, e)捕获，在Teams中显示的消息格式大概就是酱紫， logback中，消息来源于 ILoggingEvent ，通过这个对象，我们可以获取到上面title与body所需的所有信息，由于 ILoggingEvent 是一个interface，我们需要把它cast成具体的实现类从而获得更多的属性，详细代码如下， 123456789101112131415161718192021222324252627282930313233343536373839404142private MessageCard buildMessage(ILoggingEvent event) &#123; StringBuilder titleBuilder = new StringBuilder(); if (Objects.nonNull(this.titlePrefix) &amp;&amp; !\"\".equals(this.titlePrefix)) &#123; titleBuilder.append(\"[\").append(titlePrefix).append(\"]\"); &#125; titleBuilder.append(event.getFormattedMessage()); StringBuilder bodyBuilder = new StringBuilder(event.getLoggerName()); Optional.ofNullable(event.getThrowableProxy()) .map(ThrowableProxy.class::cast) .flatMap(throwableProxy -&gt; Optional.ofNullable(throwableProxy.getThrowable())) .ifPresent(throwable -&gt; &#123; bodyBuilder.append(\" - \").append(throwable.toString()); StackTraceElement[] elements = throwable.getStackTrace(); Function&lt;StackTraceElement, String&gt; mapper = traceElement -&gt; \"\\tat \" + traceElement; final Stream&lt;String&gt; traces = elements.length &gt;= this.stackTraceLines ? Stream.concat(Stream.of(elements) .limit(this.stackTraceLines) .map(mapper), Stream.of(\"\\tat ...\")) : Stream.of(elements).map(mapper); final String stackTrace = traces.collect(Collectors.joining(\"\\n\")); bodyBuilder.append(\"&lt;br&gt;&lt;pre&gt;\").append(stackTrace).append(\"&lt;/pre&gt;\"); &#125;); return MessageCard.builder() .title(titleBuilder.toString()) .text(bodyBuilder.toString()) .themeColor(getThemeColorByLevel(event.getLevel())) .build();&#125; 限制与缺点虽说Teams为我们提供了webhook的方式，但这种其终究还是一个企业级聊天平台，而非一个集中日志系统，而Connctors本身，也有一定的QPS限制，并不能及时处理海量的日志或报警，试想一下我们的系统采用大规模的集群部署或者容器化部署，在短时间内可能会产生大量的错误报警，这个时候对于Teams Connector的冲击还是非常大的。Connector的QPS限制可以参考这里。 所以在某些场景下，直接使用logback appender向Teams发送消息并不是一个非常好的选择，可以适当考虑采用ELK等集中式日志管理平台来收集日志，在出发某些特定条件，再由日志平台向Teams转发消息。 源代码请参考logback-msteams-appender-plus","tags":[{"name":"logback","slug":"logback","permalink":"https://danielpf.me/tags/logback/"},{"name":"httpclient","slug":"httpclient","permalink":"https://danielpf.me/tags/httpclient/"}]},{"title":"2020，重启博客于早春","date":"2020-04-06T12:02:59.000Z","path":"2020/04/06/kickoff2020/","text":"早在2017年，就申请了这个域名，也写下来了第一篇hexo博客，记得是使用Java 8 Stream来打印乘法口诀的，说来惭愧，之后再没有了更新。随着职业生涯的推进，感觉还是应该在某处记录下经历过的点点滴滴，也不枉费将所有的青春年华大都贡献给了架构和代码，希望自己笔耕不辍，能多留下一些足迹。 分类文章大概分成下面大类， 技巧，主要关注于某些产品或框架的特定使用，例如Java 8中的Collectors，以及Spring中的RestTemplate； 实践，主要以一个完整的项目或者用例，来实现某一个特定的功能，例如Reactive Messaging System，以及微软Teams的logback appender； 杂谈，非具体技术类主题，可能会涉及思考方式、团队管理等。 项目依据以上分类，我会在我的github上维护一些项目，这些项目包括 技巧类项目，暂时想规划下面的几个 new-age-java，新时代Java，主要介绍Java 8以后新特性的使用； spring-plain-tips，非Reactive的Spring Framework和Spring Boot的使用技巧； spring-reactive-tips，Reactive的Spring Framework和Spring Boot的使用技巧； 实践类项目，每个实践主题都会有一个新建的项目与之对应，目前有几个比较成型的，以后会陆续增加， logback-msteams-appender-plus，实现了一个微软Teams的logback appender，可以向Teams聊天软件发送日志信息； reactive-messaging-play，实现了一个full reactive的end-to-end的消息服务； cloud-gateway-auth2-play，实现了基于Spring Cloud Gateway的OAuth2鉴权； 最后也不知道自己是否能坚持下去，尽人事听天命，但行好事莫问前程。","tags":[]}]